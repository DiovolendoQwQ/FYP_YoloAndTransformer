## 总体架构

* 阶段一用 `YOLOv8` 在整图做粗检，优先召回中大型目标；按相对面积阈值筛出“大目标”框。

* 将大目标框对应区域从原图中“抠掉”（掩模或裁剪形成剩余区域/补充子图）。

* 阶段二对剩余区域做细扫：以滑动窗口/patch 的高分辨率输入，利用 Transformer 增强的检测模型聚焦小目标。

* 合并两阶段结果并用 `torchvision.ops.nms` 去重，得到最终检测。

## 现有代码可复用点

* 轻量 Transformer 注意力已实现：`modules/transformer.py` 的 `TransformerBlock` 与 `C2fTransformerWrapper` 可直接作为细扫模型的骨干增强（f:\Project\FYP\_YoloAndTransformer\modules\transformer.py:4-30, 32-52）。

* 注入与训练脚本：`scripts/inject_cbam_yolov8.py` 已支持将 Transformer 包裹到 YOLO 的 `C2f` 层并训练/验证（f:\Project\FYP\_YoloAndTransformer\scripts\inject\_cbam\_yolov8.py:34-45, 182-191）。

* 小目标评估：同脚本中集成了 `AP_small` 计算（f:\Project\FYP\_YoloAndTransformer\scripts\inject\_cbam\_yolov8.py:65-76, 231-236）。

## 阶段一：YOLO 粗检

* 模型：`ultralytics.YOLO`（现有 `yolov8n.pt`/自训权重）。

* 推理：`results = yolo(img)`；从 `results[0].boxes.xyxy`、`results[0].boxes.conf`、`results[0].boxes.cls` 取出框、分数、类别。

* 大目标筛选：以相对面积阈值 `area_ratio`（如 0.05-0.15）或绝对像素阈值；面积计算为 `(x2-x1)*(y2-y1)`。

* 注意事项：统一坐标到 `xyxy`；保留类别、分数以便后续合并。

## 区域生成：掩模与裁剪

* 掩模法：构建与原图同尺寸的二值 `mask`，将大目标区域置 0，其余置 255；`residual_img = cv2.bitwise_and(img, img, mask=mask)`。

* 裁剪法：对大目标框做外接合并，取其补集区域并分割成若干子图；或在整图上做滑窗，仅跳过落在大框内的窗口。

* 细节：为避免边界截断小目标，给大框扩 `padding`（如 4-8 像素或相对比例）。

## 阶段二：Transformer 细扫

* 方案 A（优先）：复用现有 `C2fTransformerWrapper` 构建 `yolo+transform` 检测模型，对 `residual_img` 或各 `tile` 做推理，得到细扫框。

  * 构建方法见 `build_transformer_model`（f:\Project\FYP\_YoloAndTransformer\scripts\inject\_cbam\_yolov8.py:42-45）；可调 `heads`、`dim_ff`、`dropout`、`min_size`。

  * 输入策略：

    * 滑窗：`tile_size`（如 640/768）与 `tile_stride`（如 1/2 tile），对每个窗口推理并将坐标映射回全图。

    * 或整张 `residual_img` 高分辨率推理（如 `imgsz=1024`），视显存而定。

* 方案 B（可选）：使用 `timm` 的 `swin_tiny`/`mobilevit` 提特征，接 YOLO 检测头或轻量 Anchor-free 头；仅在确认依赖可用时启用。

* 性能建议：避免对“整图”做全局自注意；尽量采用窗口注意、半精度 `half`，并按 `CUDA` 可用性切换设备。

## 结果合并与去重

* 收集 `boxes_yolo` 与 `boxes_trans`，统一到全图 `xyxy` 坐标。

* 对同类目标执行 `nms`：`final_idx = torchvision.ops.nms(boxes, scores, iou_thresh)`；按索引筛选得到 `final_boxes`。

* 若类别不同或需跨类去重，可使用 `batched_nms` 并传入类别索引。

## 训练与评估

* 数据：使用 `datasets/runtime_coco128.yaml` 或自定义数据集；小目标占比高的数据更能体现细扫优势。

* 训练：

  * 基线 YOLO 训练（粗检模型）。

  * Transformer 增强模型训练（细扫模型），脚本支持与基线同参对比输出（`dual_out` 模式）。

* 评估：同时汇报 `mAP50-95`、`mAP50`、`AP_small`；现有脚本已生成曲线与 `predictions.json`，可直接调用小目标评估函数。

## 推理脚本设计（待实现）

* 在 `scripts/` 新增 `two_stage_infer.py`：封装两阶段流程与参数。

* 常用参数：`--area_ratio`、`--padding`、`--imgsz`、`--tile_size`、`--tile_stride`、`--conf`、`--iou`、`--device`、`--use_transformer`。

* Windows 兼容：路径用 `os.path.join`；避免依赖非 Windows 兼容库；检测 `torch.cuda.is_available()` 后设设备字符串如 `cuda:0`/`cpu`。

## 性能与内存优化

* 在细扫阶段启用半精度：`model.model.half()`（显卡支持时），并对输入做 `float16`。

* 对高分辨率滑窗，按批次合并，避免单批过大导致 OOM；控制 `tile_overlap` 在 20-40% 之间兼顾召回与计算量。

## 风险与备选

* 若 `timm` 不可用，优先使用现有轻量 Transformer（`modules/transformer.py`）。

* 掩模导致背景语境丢失时，改为“滑窗不掩模”，但对位于大框内的窗口直接跳过。

* 若第二阶段召回过少，调低 `conf` 并提高 `imgsz` 或增大窗口重叠，配合更小的 `area_ratio`。

<br />

\#提示  可以使用gpu加速，已经配置好环境，详细信息看.md文件

<br />

